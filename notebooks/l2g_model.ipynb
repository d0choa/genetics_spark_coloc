{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB Exploration using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mireneisdoomed\u001b[0m (\u001b[33mopen-targets\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/irenelopez/MEGAsync/EBI/repos/genetics_etl_python/src/otg/wandb/run-20230308_094120-odc0romr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/open-targets/wandb-minimal-example/runs/odc0romr\" target=\"_blank\">blooming-paper-1</a></strong> to <a href=\"https://wandb.ai/open-targets/wandb-minimal-example\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/open-targets/wandb-minimal-example\" target=\"_blank\">https://wandb.ai/open-targets/wandb-minimal-example</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/open-targets/wandb-minimal-example/runs/odc0romr\" target=\"_blank\">https://wandb.ai/open-targets/wandb-minimal-example/runs/odc0romr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▄▁█▆▇▇▇▇</td></tr><tr><td>loss</td><td>█▄▃▁▁▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.72942</td></tr><tr><td>loss</td><td>0.22413</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-paper-1</strong> at: <a href=\"https://wandb.ai/open-targets/wandb-minimal-example/runs/odc0romr\" target=\"_blank\">https://wandb.ai/open-targets/wandb-minimal-example/runs/odc0romr</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230308_094120-odc0romr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "wandb.init(\n",
    "    project=\"wandb-minimal-example\",\n",
    "    \n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# training with mock data\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# this needs to be done in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB Exploration Using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")\n",
    "xgb_classifier = SparkXGBClassifier(\n",
    "  label_col=\"indexedLabel\",\n",
    "  missing=0.0,\n",
    "  n_estimators = 20\n",
    ")\n",
    "pipeline = Pipeline(stages=[indexer, xgb_classifier])\n",
    "model = pipeline.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import wandb\n",
    "\n",
    "scoreAndLabels = map(\n",
    "\tlambda x: (\n",
    "\t\tVectors.dense([1.0 - x[0], x[0]]), x[1], x[2]),\n",
    "    \t\t\t      [(0.1, 0.0, 0.0), (0.1, 1.0, 0.0), \n",
    "\t\t\t       (0.4, 0.0, 0.0), (0.6, 0.0, 0.1), \n",
    "\t\t\t       (0.6, 1.0, 1.0), (0.6, 1.0, 0.0), \n",
    "                               (0.8, 1.0, 1.0)])\n",
    "dataset = spark.createDataFrame(scoreAndLabels, [\"probability\", \"label\", \"prediction\"])\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "run = wandb.init(project = \"sparkml-example\", \n",
    "\t\t job_type = \"multiclass-classification-eval\")\n",
    "wandb_evaluator = WandbEvaluator(sparkMlEvaluator = evaluator)\n",
    "wandb_evaluator.setWandbRun(run)\n",
    "wandb_evaluator.setMetricPrefix(\"test/\")\n",
    "wandb_evaluator.evaluate(dataset)\n",
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")\n",
    "xgb_classifier = SparkXGBClassifier(\n",
    "  label_col=\"indexedLabel\",\n",
    "  missing=0.0,\n",
    "  n_estimators = 20\n",
    ")\n",
    "pipeline = Pipeline(stages=[indexer, xgb_classifier])\n",
    "# Create an evaluator.  In this case, use \"weightedPrecision\".\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "\tlabelCol=\"indexedLabel\", \n",
    "\tmetricName=\"weightedPrecision\"\n",
    ")\n",
    "wandb_evaluator = WandbEvaluator(sparkMlEvaluator = evaluator, metricPrefix = \"cv/\")\n",
    "\n",
    "\n",
    "grid = ParamGridBuilder() \\\n",
    "  .addGrid(xgb_classifier.learning_rate, [0.0, 0.01, 0.1]) \\\n",
    "  .addGrid(xgb_classifier.max_depth, [2, 3, 5]) \\\n",
    "  .build()\n",
    "\n",
    "\n",
    "cv = WandbCrossValidator(estimator=pipeline, \n",
    "                         evaluator=wandb_evaluator, \n",
    "                         estimatorParamMaps=grid, \n",
    "                         numFolds=3)\n",
    "cv.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create mock data\n",
    "num_rows = 1000\n",
    "num_cols = 10\n",
    "data = np.random.rand(num_rows, num_cols + 1)\n",
    "columns = [f'feature_{str(i)}' for i in range(num_cols)] + ['label']\n",
    "df = pd.DataFrame(data=data, columns=columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 45\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 45\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/irenelopez/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/irenelopez/MEGAsync/EBI/repos/genetics_etl_python/src/otg/wandb/run-20230308_093817-2nm0qn9d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/open-targets/xgboost-spark-example/runs/2nm0qn9d\" target=\"_blank\">robust-silence-1</a></strong> to <a href=\"https://wandb.ai/open-targets/xgboost-spark-example\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/open-targets/xgboost-spark-example\" target=\"_blank\">https://wandb.ai/open-targets/xgboost-spark-example</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/open-targets/xgboost-spark-example/runs/2nm0qn9d\" target=\"_blank\">https://wandb.ai/open-targets/xgboost-spark-example/runs/2nm0qn9d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pyspark.ml.regression' has no attribute 'XGBoostRegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m train_data, test_data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mrandomSplit([\u001b[39m0.8\u001b[39m, \u001b[39m0.2\u001b[39m], seed\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39m# Train XGBoost model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m xgb \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39;49mXGBoostRegressor()\n\u001b[1;32m     21\u001b[0m xgb_params \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39meta\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmaxDepth\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m3\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mreg:squarederror\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumRound\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m10\u001b[39m}\n\u001b[1;32m     22\u001b[0m xgb\u001b[39m.\u001b[39msetParams(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mxgb_params)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyspark.ml.regression' has no attribute 'XGBoostRegressor'"
     ]
    }
   ],
   "source": [
    "import pyspark.ml.feature as ft\n",
    "import pyspark.ml.regression as reg\n",
    "import wandb\n",
    "\n",
    "wandb.init(project='xgboost-spark-example', )\n",
    "\n",
    "# Load data\n",
    "data = spark.createDataFrame(df)\n",
    "\n",
    "# Prepare data for model training\n",
    "feature_cols = data.columns[:-1]\n",
    "label_col = data.columns[-1]\n",
    "assembler = ft.VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data = assembler.transform(data).select(\"features\", label_col)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=123)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb = reg.XGBoostRegressor()\n",
    "xgb_params = {\"eta\": 0.1, \"maxDepth\": 3, \"objective\": \"reg:squarederror\", \"numRound\": 10}\n",
    "xgb.setParams(**xgb_params)\n",
    "model = xgb.fit(train_data)\n",
    "\n",
    "# Evaluate model\n",
    "predictions = model.transform(test_data)\n",
    "rmse_evaluator = reg.RegressionEvaluator(labelCol=label_col, metricName=\"rmse\")\n",
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "\n",
    "# Log results to Weights and Biases\n",
    "wandb.log({\"rmse\": rmse})\n",
    "\n",
    "# Save model to Weights and Biases\n",
    "model_path = \"xgboost_pyspark_ml_model\"\n",
    "model.save(model_path)\n",
    "wandb.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /var/folders/54/2j7x_lqn343_d6hjm7mcv9rc0000gn/T/ipykernel_80237/3518243712.py 10 <module>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/irenelopez/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 1108, in init\n",
      "    run = wi.init()\n",
      "  File \"/Users/irenelopez/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 576, in init\n",
      "    manager._inform_init(settings=self.settings, run_id=self.settings.run_id)\n",
      "  File \"/Users/irenelopez/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py\", line 174, in _inform_init\n",
      "    svc_iface._svc_inform_init(settings=settings, run_id=run_id)\n",
      "  File \"/Users/irenelopez/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/service/service_sock.py\", line 38, in _svc_inform_init\n",
      "    self._sock_client.send(inform_init=inform_init)\n",
      "  File \"/Users/irenelopez/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 211, in send\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/Users/irenelopez/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/Users/irenelopez/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/Users/irenelopez/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "problem",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:1108\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1108\u001b[0m     run \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39;49minit()\n\u001b[1;32m   1109\u001b[0m     except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n",
      "File \u001b[0;32m~/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:576\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39msetting up manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 576\u001b[0m     manager\u001b[39m.\u001b[39;49m_inform_init(settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings, run_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings\u001b[39m.\u001b[39;49mrun_id)\n\u001b[1;32m    578\u001b[0m mailbox \u001b[39m=\u001b[39m Mailbox()\n",
      "File \u001b[0;32m~/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py:174\u001b[0m, in \u001b[0;36m_Manager._inform_init\u001b[0;34m(self, settings, run_id)\u001b[0m\n\u001b[1;32m    173\u001b[0m svc_iface \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_service_interface()\n\u001b[0;32m--> 174\u001b[0m svc_iface\u001b[39m.\u001b[39;49m_svc_inform_init(settings\u001b[39m=\u001b[39;49msettings, run_id\u001b[39m=\u001b[39;49mrun_id)\n",
      "File \u001b[0;32m~/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/service/service_sock.py:38\u001b[0m, in \u001b[0;36mServiceSockInterface._svc_inform_init\u001b[0;34m(self, settings, run_id)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock_client\n\u001b[0;32m---> 38\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock_client\u001b[39m.\u001b[39;49msend(inform_init\u001b[39m=\u001b[39;49minform_init)\n",
      "File \u001b[0;32m~/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py:211\u001b[0m, in \u001b[0;36mSockClient.send\u001b[0;34m(self, inform_init, inform_start, inform_attach, inform_finish, inform_teardown)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munmatched\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 211\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend_server_request(server_req)\n",
      "File \u001b[0;32m~/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_server_request\u001b[39m(\u001b[39mself\u001b[39m, msg: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_message(msg)\n",
      "File \u001b[0;32m~/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sendall_with_error_handle(header \u001b[39m+\u001b[39;49m data)\n",
      "File \u001b[0;32m~/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49msend(data)\n\u001b[1;32m    131\u001b[0m     \u001b[39m# sent equal to 0 indicates a closed socket\u001b[39;00m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkSession\n\u001b[1;32m      9\u001b[0m \u001b[39m# Set up WandB\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m wandb\u001b[39m.\u001b[39;49minit(project\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwandb-spark-example\u001b[39;49m\u001b[39m\"\u001b[39;49m,)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Load the data\u001b[39;00m\n\u001b[1;32m     13\u001b[0m data \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mcreateDataFrame(df)\n",
      "File \u001b[0;32m~/MEGAsync/EBI/repos/genetics_etl_python/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:1145\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[39mif\u001b[39;00m except_exit:\n\u001b[1;32m   1144\u001b[0m             os\u001b[39m.\u001b[39m_exit(\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1145\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mproblem\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror_seen\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39mreturn\u001b[39;00m run\n",
      "\u001b[0;31mException\u001b[0m: problem"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "\n",
    "wandb.init(project=\"wandb-spark-example\",)\n",
    "\n",
    "data = spark.createDataFrame(df)\n",
    "\n",
    "# Prepare the data\n",
    "assembler = VectorAssembler(inputCols=['feature1', 'feature2', 'feature3'], outputCol='features')\n",
    "data = assembler.transform(data).select(['features', 'label'])\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2])\n",
    "\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "model = lr.fit(train_data)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.transform(test_data)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction')\n",
    "auc = evaluator.evaluate(predictions)\n",
    "wandb.log({'auc': auc})\n",
    "\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
